{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS-Project2(KFLDA).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gmt-3Wnwl6lF"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.utils.validation import check_X_y\n",
        "from sklearn.utils.validation import check_array\n",
        "from sklearn.metrics.pairwise import pairwise_kernels\n",
        "from numpy.linalg import inv, det\n",
        "from scipy.linalg import eigh\n",
        "# import warnings"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_UkYtM-meEY"
      },
      "source": [
        "class KFDA():\n",
        "    \n",
        "    \"\"\"\n",
        "    Kernel Fisher Discriminant Analysis (KFDA)\n",
        "    Discriminant Analysis in high dimensionality using the kernel trick.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    n_components : int, the amount of Fisher directions to use.\n",
        "        default=2\n",
        "        This is limited by the amount of classes minus one.\n",
        "        Number of components (lower than number of classes -1) for dimensionality reduction.\n",
        "\n",
        "    kernel : str, [\"linear\" | \"poly\" | \"rbf\" | \"sigmoid\" | \"cosine\" | \"precomputed\"]\n",
        "        default=\"linear\".\n",
        "        The kernel to use.\n",
        "        Use **kwds to pass arguments to these functions.\n",
        "        See\n",
        "        https://scikit-learn.org/stable/modules/metrics.html#polynomial-kernel\n",
        "        for more details.\n",
        "    \n",
        "    alpha : float, default=1e-3\n",
        "        Regularization term for singular within-class matrix.\n",
        "      \n",
        "    tol : float, default=1e-4\n",
        "        Singularity toleration level.\n",
        "\n",
        "    kprms : mapping of string to any, default=None\n",
        "        parameters to pass to the kernel function.\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    X_ : Training vector after applying input validation\n",
        "\n",
        "    y_ : label vector after applying input validation\n",
        "\n",
        "    W_ : array of shape (n_components) \n",
        "        contains weights of eigen vectors\n",
        "    \n",
        "    unique_classes : array of shape (n_classes,)\n",
        "        The unique class labels\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,n_components=2, kernel='linear', alpha=1e-3, tol=1e-4, **kprms):\n",
        "\n",
        "        self.n_components_ = n_components\n",
        "        self.kernel_ = kernel\n",
        "        self.alpha_ = alpha\n",
        "        self.tol_ = tol\n",
        "        self.kernel_params_ = kprms\n",
        "        \n",
        "        #checking kernel parameter and assinging default value if kernel is None or obj\n",
        "        if kernel is None or callable(kernel):\n",
        "            self.kernel_ = 'linear'\n",
        "    \n",
        "\n",
        "    def get_kernel_(self, X, Y=None):\n",
        "        if callable(self.kernel_):\n",
        "            params = self.kernel_params_ or {}\n",
        "        else:\n",
        "            params = self.kernel_params_\n",
        "\n",
        "        return pairwise_kernels(X, Y, metric=self.kernel_, filter_params=True, **params)\n",
        "\n",
        "    def fit(self, X,y):\n",
        "      \n",
        "\n",
        "      \"\"\"\n",
        "        Fit the model from the data in X and the labels in y.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape (N x d)\n",
        "            Training vector, where N is the number of samples, and d is the number of features.\n",
        "        y : array-like, shape (N)\n",
        "            Labels vector, where N is the number of samples.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns the instance itself.\n",
        "      \"\"\"\n",
        "\n",
        "      X_, y_ = check_X_y(X,y)\n",
        "      self.X_, self.y_ = X_, y_\n",
        "      n, d = X_.shape\n",
        "\n",
        "      K = self.get_kernel_(X_)\n",
        "\n",
        "      if self.n_components_ is None:\n",
        "          ndims = d\n",
        "      else:\n",
        "          ndims = self.n_components_\n",
        "\n",
        "      self.unique_classes, class_counts = np.unique(y, return_counts=True)\n",
        "      ndims = min(ndims, len(self.unique_classes) - 1)\n",
        "\n",
        "      # Compute M and N matrices\n",
        "      M_avg = K.sum(axis=1) / n\n",
        "      M = np.zeros([n, n])\n",
        "      N = np.zeros([n, n])\n",
        "      for i, c in enumerate(self.unique_classes):\n",
        "          C_i = np.where(y == c)[0]\n",
        "          K_i = K[:, C_i]\n",
        "          M_i = K_i.sum(axis=1) / class_counts[i]\n",
        "          diff = (M_i - M_avg)\n",
        "          M += class_counts[i] * (diff @ diff.T)\n",
        "          const_ni = np.full([class_counts[i], class_counts[i]], 1.0 - 1.0 / class_counts[i])\n",
        "          N += K_i @ const_ni @ K_i.T\n",
        "\n",
        "      # Regularize matrix N with alpha_\n",
        "      if abs(det(N)) < self.tol_:\n",
        "          N += self.alpha_ * np.eye(n)\n",
        "      \n",
        "      # Calculate Eigen Values and Vectors\n",
        "      evals, evecs = eigh(inv(N) @ M)\n",
        "      evecs = evecs[:, np.argsort(evals)[::-1]]\n",
        "\n",
        "      # Return Top ndims Eigen Vectors\n",
        "      self.W_ = evecs[:, :ndims].T\n",
        "      return self\n",
        "\n",
        "    def transform(self,X=None):\n",
        "\n",
        "      \"\"\"\n",
        "      Applies the kernel transformation.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : (N x d) matrix, optional\n",
        "            Data to transform. If not supplied, the training data will be used.\n",
        "        Returns\n",
        "        -------\n",
        "        transformed: (N x d') matrix.\n",
        "            Input data transformed by the learned mapping.\n",
        "      \"\"\"\n",
        "\n",
        "      if X is None:\n",
        "          X = self.X_\n",
        "      else:\n",
        "          X = check_array(X, accept_sparse=True)\n",
        "\n",
        "      # calculate K for X and X~\n",
        "      K = self.get_kernel_(X,self.X_)\n",
        "      return K @ self.W_.T\n",
        "        "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UeP1dC1ydpz",
        "outputId": "26ada010-a186-404a-8d9f-6624f560a710"
      },
      "source": [
        "y=np.array([1,1,1,1,1,2,2,2,2,2,2])\n",
        "X=np.array([[1,2],[2,3],[3,3],[4,5],[5,5],[1,0],[2,1],[3,1],[3,2],[5,3],[6,5]])\n",
        "X"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [2, 3],\n",
              "       [3, 3],\n",
              "       [4, 5],\n",
              "       [5, 5],\n",
              "       [1, 0],\n",
              "       [2, 1],\n",
              "       [3, 1],\n",
              "       [3, 2],\n",
              "       [5, 3],\n",
              "       [6, 5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGyqmFJjyjQr",
        "outputId": "e63c5920-34f1-41b8-e719-2b2691733354"
      },
      "source": [
        "obj = KFDA(n_components=1,kernel='linear')\n",
        "obj.fit(X,y)\n",
        "obj.W_"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.34981293, -0.32609751, -0.28463864, -0.21331655, -0.1413142 ,\n",
              "        -0.50645435, -0.38295741, -0.24773259, -0.23189846,  0.11472165,\n",
              "         0.30551063]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxAOCbTX05iU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "920ac354-51b8-4bf2-d2da-9631196b6e9e"
      },
      "source": [
        "obj.transform()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-10.77586516],\n",
              "       [-18.02397343],\n",
              "       [-21.7443248 ],\n",
              "       [-32.52018996],\n",
              "       [-36.24054134],\n",
              "       [ -3.72035137],\n",
              "       [-10.96845964],\n",
              "       [-14.68881101],\n",
              "       [-18.2165679 ],\n",
              "       [-29.18502754],\n",
              "       [-39.96089271]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW9QS9PW1_6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d3da5a-40c3-472b-8b8e-1f74d9b934f7"
      },
      "source": [
        "y=np.array ([ 1, 1, 1, 1, 2, 2, 2 ])\r\n",
        "X=np.array ([[2, 3], [3, 3], [4, 5], [5, 5], [1, 0], [2 ,1], [3, 1]])\r\n",
        "kfda = KFDA( n_components = 1 , kernel = \"linear\")\r\n",
        "kfda.fit (X, y)\r\n",
        "kfda.W_"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.46499795, -0.34924755, -0.28050306, -0.00799093, -0.65249595,\n",
              "        -0.35993865,  0.16658463]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CYtHUun4AcY",
        "outputId": "eb6e32ae-8382-4f51-9265-ce51b07dd814"
      },
      "source": [
        "kfda = KFDA( n_components = 2 , kernel = \"linear\")\r\n",
        "kfda.fit (X, y)\r\n",
        "trans=kfda.transform()\r\n",
        "trans"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-20.26033083],\n",
              "       [-24.2726556 ],\n",
              "       [-36.44210123],\n",
              "       [-40.454426  ],\n",
              "       [ -4.01232477],\n",
              "       [-12.10320997],\n",
              "       [-16.11553474]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQihpIpS5WfP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}